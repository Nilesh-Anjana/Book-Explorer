// scraper.js
const puppeteer = require('puppeteer');
const mongoose = require('mongoose');
const Book = require('./models/book');
require('dotenv').config();

// The main scraping function, which is now reusable.
async function scrapeBooksToScrape() {
Â  console.log('ğŸš€ Starting scraper...');
Â  const browser = await puppeteer.launch({
Â  Â  headless: true,
Â  Â  args: ['--no-sandbox', '--disable-setuid-sandbox'],
Â  });
Â  const page = await browser.newPage();
Â  let currentPage = 1;
Â  let hasNextPage = true;
Â  let allBooks = [];

Â  while (hasNextPage) {
Â  Â  console.log(`ğŸ“– Scraping page ${currentPage}...`);
Â  Â  const url = currentPage === 1
Â  Â  Â  ? 'https://books.toscrape.com/'
Â  Â  Â  : `https://books.toscrape.com/catalogue/page-${currentPage}.html`;
Â  Â  try {
Â  Â  Â  await page.goto(url, { waitUntil: 'networkidle2', timeout: 60000 });
Â  Â  Â  console.log(`ğŸŒ Loaded: ${url}`);
Â  Â  } catch (err) {
Â  Â  Â  console.error(`âŒ Failed to load page ${currentPage}:`, err.message);
Â  Â  Â  break;
Â  Â  }

Â  Â  const books = await page.evaluate(() => {
Â  Â  Â  const bookElements = document.querySelectorAll('.product_pod');
Â  Â  Â  return Array.from(bookElements).map(book => {
Â  Â  Â  Â  const title = book.querySelector('h3 a')?.getAttribute('title') || '';
Â  Â  Â  Â  const priceText = book.querySelector('.price_color')?.textContent || 'Â£0';
Â  Â  Â  Â  const price = parseFloat(priceText.replace('Â£', ''));
Â  Â  Â  Â  const stockText = book.querySelector('.instock.availability')?.textContent.trim() || '';
Â  Â  Â  Â  const stock = stockText.includes('In stock') ? 'In stock' : 'Out of stock';
Â  Â  Â  Â  const ratingClass = book.querySelector('p[class*="star-rating"]')?.className || '';
Â  Â  Â  Â  const ratingMap = { 'One': 1, 'Two': 2, 'Three': 3, 'Four': 4, 'Five': 5 };
Â  Â  Â  Â  const rating = ratingMap[ratingClass.split(' ')[1]] || 0;
Â  Â  Â  Â  const detailUrl = 'https://books.toscrape.com/' + book.querySelector('h3 a')?.getAttribute('href');
Â  Â  Â  Â  const imageUrl = 'https://books.toscrape.com/' + book.querySelector('img')?.getAttribute('src');
Â  Â  Â  Â  return { title, price, stock, rating, detailUrl, imageUrl };
Â  Â  Â  });
Â  Â  });

Â  Â  allBooks.push(...books);
Â  Â  console.log(`âœ… Found ${books.length} books on page ${currentPage}`);
Â  Â  hasNextPage = await page.$('.next') !== null;
Â  Â  console.log(`â¡ï¸ Has next page: ${hasNextPage}`);
Â  Â  currentPage++;
Â  }

Â  console.log(`ğŸ’¾ Saving ${allBooks.length} books to database...`);
Â  await Book.deleteMany({});
Â  await Book.insertMany(allBooks);

Â  console.log('âœ… Scraping completed successfully!');
Â  await browser.close();
Â  // Close the Mongoose connection after the scrape is done
Â  if (mongoose.connection.readyState === 1) {
Â  Â  await mongoose.connection.close();
Â  Â  console.log('ğŸ”Œ MongoDB connection closed.');
Â  }
}

module.exports = { scrapeBooksToScrape };