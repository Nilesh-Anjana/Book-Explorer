const puppeteer = require('puppeteer'); 
const mongoose = require('mongoose');
const Book = require('./models/book');
require('dotenv').config();

// Connect to MongoDB
mongoose.connect(process.env.MONGODB_URI);

async function scrapeBooksToScrape() {
  console.log('ğŸš€ Starting scraper...');

  const browser = await puppeteer.launch({
    headless: true, 
    args: ['--no-sandbox', '--disable-setuid-sandbox'],
  });

  const page = await browser.newPage();

  let currentPage = 1;
  let hasNextPage = true;
  let allBooks = [];

  while (hasNextPage) {
    console.log(`ğŸ“– Scraping page ${currentPage}...`);

    const url = currentPage === 1
      ? 'https://books.toscrape.com/'
      : `https://books.toscrape.com/catalogue/page-${currentPage}.html`;

    try {
      await page.goto(url, { waitUntil: 'networkidle2', timeout: 60000 });
      console.log(`ğŸŒ Loaded: ${url}`);
    } catch (err) {
      console.error(`âŒ Failed to load page ${currentPage}:`, err.message);
      break;
    }

    // Extract book data
    const books = await page.evaluate(() => {
      const bookElements = document.querySelectorAll('.product_pod');

      return Array.from(bookElements).map(book => {
        const title = book.querySelector('h3 a')?.getAttribute('title') || '';
        const priceText = book.querySelector('.price_color')?.textContent || 'Â£0';
        const price = parseFloat(priceText.replace('Â£', ''));

        const stockText = book.querySelector('.instock.availability')?.textContent.trim() || '';
        const stock = stockText.includes('In stock') ? 'In stock' : 'Out of stock';

        const ratingClass = book.querySelector('p[class*="star-rating"]')?.className || '';
        const ratingMap = { 'One': 1, 'Two': 2, 'Three': 3, 'Four': 4, 'Five': 5 };
        const rating = ratingMap[ratingClass.split(' ')[1]] || 0;

        const detailUrl = 'https://books.toscrape.com/' +
          book.querySelector('h3 a')?.getAttribute('href');
        const imageUrl = 'https://books.toscrape.com/' +
          book.querySelector('img')?.getAttribute('src');

        return { title, price, stock, rating, detailUrl, imageUrl };
      });
    });

    allBooks.push(...books);
    console.log(`âœ… Found ${books.length} books on page ${currentPage}`);

    hasNextPage = await page.$('.next') !== null;
    console.log(`â¡ï¸ Has next page: ${hasNextPage}`);
    currentPage++;
  }

  console.log(`ğŸ’¾ Saving ${allBooks.length} books to database...`);
  await Book.deleteMany({});
  await Book.insertMany(allBooks);

  console.log('âœ… Scraping completed successfully!');
  await browser.close();
  mongoose.connection.close();
}

// Call the function (was commented out earlier)
scrapeBooksToScrape()
  .then(() => console.log("ğŸ‰ Done"))
  .catch(err => console.error("âŒ Error in scraper:", err));
